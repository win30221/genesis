package gemini

import (
	"context"
	"encoding/json"
	"fmt"
	"genesis/pkg/llm"
	"log"
	"strings"

	"google.golang.org/genai"
)

// GeminiClient Google Gemini API å®¢æˆ¶ç«¯
type GeminiClient struct {
	client *genai.Client
	model  string
}

// NewGeminiClient å‰µå»ºå–®ä¸€æ¨¡å‹/å–®ä¸€ Key çš„ Gemini å®¢æˆ¶ç«¯
func NewGeminiClient(apiKey string, model string, useThought bool) *GeminiClient {
	ctx := context.Background()
	client, err := genai.NewClient(ctx, &genai.ClientConfig{
		APIKey:  apiKey,
		Backend: genai.BackendGeminiAPI,
	})
	if err != nil {
		log.Fatalf("âŒ Fatal: Failed to create Gemini client: %v", err)
	}

	return &GeminiClient{
		client: client,
		model:  model,
	}
}

func (g *GeminiClient) Provider() string {
	return "gemini"
}

// æ ¼å¼åŒ– ModalityTokenCount é™£åˆ—
func formatModality(details []*genai.ModalityTokenCount) string {
	if len(details) == 0 {
		return "0"
	}
	var res []string
	for _, d := range details {
		res = append(res, fmt.Sprintf("%v: %d", d.Modality, d.TokenCount))
	}
	return strings.Join(res, " | ")
}

// StreamChat å¯¦ä½œ LLMClient.StreamChat
func (g *GeminiClient) StreamChat(ctx context.Context, messages []llm.Message, availableTools any) (<-chan llm.StreamChunk, error) {
	// è½‰æ›è¨Šæ¯
	apiMessages, systemInstruction := g.convertMessages(messages)

	// è½‰æ›å·¥å…·
	var genaiTools []*genai.Tool
	if availableTools != nil {
		if tools, ok := availableTools.([]map[string]any); ok {
			var fds []*genai.FunctionDeclaration
			for _, t := range tools {
				fd := &genai.FunctionDeclaration{
					Name:        t["name"].(string),
					Description: t["description"].(string),
				}
				if params, ok := t["parameters"].(map[string]any); ok {
					schemaB, _ := json.Marshal(params)
					var schema genai.Schema
					json.Unmarshal(schemaB, &schema)
					fd.Parameters = &schema
				}
				fds = append(fds, fd)
			}
			if len(fds) > 0 {
				genaiTools = append(genaiTools, &genai.Tool{
					FunctionDeclarations: fds,
				})
			}
		}
	}

	chunkCh := make(chan llm.StreamChunk, 100)
	startResultCh := make(chan error, 1) // Unbuffered to detect if reader is present

	// log.Printf("[Gemini] ğŸŒŠ Streaming with model: %s...", g.model)
	log.Printf("[Gemini] ğŸŒŠ Streaming with model: %s...", g.model)

	go func() {
		defer close(chunkCh)

		iter := g.client.Models.GenerateContentStream(ctx, g.model, apiMessages, &genai.GenerateContentConfig{
			SystemInstruction: systemInstruction,
			Tools:             genaiTools,
			ThinkingConfig: &genai.ThinkingConfig{
				IncludeThoughts: true,
			},
		})

		started := false
		var lastUsage *llm.LLMUsage

		for resp, err := range iter {
			if err != nil {
				// å˜—è©¦å„ªå…ˆè™•ç†æœ€å¾Œä¸€æ¬¡ resp (å¦‚æœæœ‰çš„è©±)
				// Google GenAI SDK è¿­ä»£å™¨å¯èƒ½åœ¨è¿”å›éŒ¯èª¤çš„åŒæ™‚è¿”å›æœ€å¾Œä¸€é»è³‡æ–™
				if resp == nil {
					log.Printf("Gemini Stream Error: %v", err)
					if !started {
						startResultCh <- err
					} else {
						// Stream ä¸­æ–·ï¼Œé€šçŸ¥ä½¿ç”¨è€…
						chunkCh <- llm.NewTextChunk(fmt.Sprintf("\nâŒ Stream interrupted: %v", err))
					}
					break
				}
				// å¦‚æœ err != nil ä½† resp != nilï¼Œç¹¼çºŒè™•ç†é€™æ¬¡çš„ respï¼Œç„¶å¾Œåœ¨ä¸‹ä¸€æ¬¡è¿­ä»£æˆ–æ˜¯é€™è£¡è™•ç†éŒ¯èª¤
				// æ ¹æ“š Go iterator æ…£ä¾‹ï¼Œé€™è£¡æˆ‘å€‘è¨˜éŒ„éŒ¯èª¤ä½†ç¹¼çºŒè™•ç†ç•¶å‰æ•¸æ“š
				log.Printf("Gemini Stream Error (with data): %v", err)
			}

			if !started {
				started = true
				startResultCh <- nil // ç¬¬ä¸€å€‹ chunk æˆåŠŸ
			}

			// Capture Usage Metadata (usually in the last chunk)
			if resp.UsageMetadata != nil {
				u := resp.UsageMetadata
				lastUsage = &llm.LLMUsage{
					PromptTokens:     int(u.PromptTokenCount),
					PromptDetail:     formatModality(u.PromptTokensDetails),
					CompletionTokens: int(u.CandidatesTokenCount),
					CompletionDetail: formatModality(u.CandidatesTokensDetails),
					TotalTokens:      int(u.TotalTokenCount),
					ThoughtsTokens:   int(u.ThoughtsTokenCount),
					CachedTokens:     int(u.CachedContentTokenCount),
				}
			}

			for _, candidate := range resp.Candidates {
				if candidate.FinishReason != "" && lastUsage != nil {
					lastUsage.StopReason = string(candidate.FinishReason)
				}

				if candidate.Content != nil {
					var blocks []llm.ContentBlock
					var toolCalls []llm.ToolCall

					for _, part := range candidate.Content.Parts {
						if part.Text != "" {
							if part.Thought {
								// æ€è€ƒå…§å®¹
								blocks = append(blocks, llm.ContentBlock{
									Type: "thinking",
									Text: part.Text,
								})
							} else {
								// æ­£å¸¸å›æ‡‰
								blocks = append(blocks, llm.ContentBlock{
									Type: "text",
									Text: part.Text,
								})
							}
						}

						if part.FunctionCall != nil {
							// å·¥å…·èª¿ç”¨
							argsB, _ := json.Marshal(part.FunctionCall.Args)
							toolCalls = append(toolCalls, llm.ToolCall{
								ID:   "", // Gemini ä¸²æµä¸­ ID æœ‰æ™‚ä¸åœ¨æ­¤è™•
								Name: part.FunctionCall.Name,
								Function: llm.FunctionCall{
									Name:      part.FunctionCall.Name,
									Arguments: string(argsB),
								},
								// ä¿å­˜å®Œæ•´çš„ FunctionCall ä»¥ä¾¿å¾ŒçºŒé‡å»ºï¼ˆåŒ…å« thought_signature ç­‰éš±è—æ¬„ä½ï¼‰
								Meta: map[string]any{
									"gemini_function_call": part.FunctionCall,
								},
							})
							log.Printf("[Gemini] ğŸ› ï¸ Tool Call: %s(%s)", part.FunctionCall.Name, string(argsB))
						}
					}

					if len(blocks) > 0 || len(toolCalls) > 0 {
						chunkCh <- llm.StreamChunk{
							ContentBlocks: blocks,
							ToolCalls:     toolCalls,
						}
					}
				}
			}
		}

		// ç™¼é€æœ€çµ‚ chunkï¼ˆå¸¶ç”¨é‡çµ±è¨ˆï¼‰
		if lastUsage != nil {
			chunkCh <- llm.NewFinalChunk(lastUsage.StopReason, lastUsage)
			llm.LogUsage(g.model, lastUsage)
		}
	}()

	// ç­‰å¾…åˆå§‹åŒ–çµæœ (ç¬¬ä¸€å€‹ chunk æˆ–ç«‹å³å ±éŒ¯)
	select {
	case err := <-startResultCh:
		if err != nil {
			return nil, err
		}
		return chunkCh, nil
	case <-ctx.Done():
		return nil, ctx.Err()
	}
}

// convertMessages è½‰æ›è¨Šæ¯åˆ—è¡¨
func (g *GeminiClient) convertMessages(messages []llm.Message) ([]*genai.Content, *genai.Content) {
	var genaiContents []*genai.Content
	var systemInstruction *genai.Content

	for _, msg := range messages {
		if msg.Role == "system" {
			// System ä½œç‚º SystemInstruction
			var parts []*genai.Part
			for _, block := range msg.Content {
				if block.Type == "text" && block.Text != "" {
					parts = append(parts, &genai.Part{Text: block.Text})
				}
			}
			if len(parts) > 0 {
				systemInstruction = &genai.Content{Parts: parts}
			}
			continue
		}

		role := "user"
		if msg.Role == "assistant" {
			role = "model"
		}

		if msg.Role == "tool" {
			role = "user" // Gemini ä¸­å·¥å…·çµæœæ˜¯ user role çš„ä¸€éƒ¨åˆ†
			genaiContents = append(genaiContents, &genai.Content{
				Role: role,
				Parts: []*genai.Part{
					{
						FunctionResponse: &genai.FunctionResponse{
							Name:     msg.Role, // å…¶å¯¦æ‡‰è©²æ˜¯å·¥å…·åç¨±ï¼Œé€™è£¡æš«æ™‚ç°¡åŒ–
							Response: map[string]any{"result": msg.Content[0].Text},
						},
					},
				},
			})
			continue
		}

		var parts []*genai.Part
		// å…ˆæª¢æŸ¥æ˜¯å¦æœ‰èˆŠçš„ ToolCall (å¦‚æœæœ‰ï¼ŒGemini éœ€è¦å›å‚³å°æ‡‰çš„ FunctionCall)
		if len(msg.ToolCalls) > 0 {
			for _, tc := range msg.ToolCalls {
				// å„ªå…ˆä½¿ç”¨ä¿å­˜çš„åŸå§‹ FunctionCallï¼ˆåŒ…å« thought_signatureï¼‰
				if tc.Meta != nil {
					if originalFC, ok := tc.Meta["gemini_function_call"].(*genai.FunctionCall); ok {
						parts = append(parts, &genai.Part{
							FunctionCall: originalFC,
						})
						continue
					}
				}

				// å¦‚æœæ²’æœ‰ä¿å­˜çš„åŸå§‹è³‡æ–™ï¼Œå‰‡æ‰‹å‹•é‡å»ºï¼ˆå¯èƒ½æœƒç¼ºå°‘ thought_signatureï¼‰
				var args map[string]any
				json.Unmarshal([]byte(tc.Function.Arguments), &args)
				parts = append(parts, &genai.Part{
					FunctionCall: &genai.FunctionCall{
						Name: tc.Function.Name,
						Args: args,
					},
				})
			}
		}

		for _, block := range msg.Content {
			switch block.Type {
			case "text":
				if block.Text == "" {
					continue // ç•¥éç©ºæ–‡æœ¬
				}
				parts = append(parts, &genai.Part{Text: block.Text})

			case "thinking":
				if block.Text == "" {
					continue
				}
				// å„²å­˜æ™‚æ€è€ƒå…§å®¹æ¨™è¨˜ç‚º Thought
				parts = append(parts, &genai.Part{
					Text:    block.Text,
					Thought: true,
				})

			case "image":
				if block.Source != nil && len(block.Source.Data) > 0 {
					parts = append(parts, &genai.Part{
						InlineData: &genai.Blob{
							MIMEType: block.Source.MediaType,
							Data:     block.Source.Data,
						},
					})
				}
			}
		}

		if len(parts) > 0 {
			genaiContents = append(genaiContents, &genai.Content{
				Role:  role,
				Parts: parts,
			})
		}
	}

	return genaiContents, systemInstruction
}

// IsTransientError å¯¦ä½œ LLMClient ä»‹é¢
func (g *GeminiClient) IsTransientError(err error) bool {
	if err == nil {
		return false
	}
	errMsg := err.Error()

	// 1. Google API å¸¸è¦‹çš„ 503 Service Unavailable / Overloaded
	if strings.Contains(errMsg, "503") || strings.Contains(strings.ToLower(errMsg), "overloaded") {
		return true
	}

	// 2. 429 Too Many Requests (Rate Limit)
	if strings.Contains(errMsg, "429") || strings.Contains(strings.ToLower(errMsg), "resource exhausted") {
		return true
	}

	return false
}
